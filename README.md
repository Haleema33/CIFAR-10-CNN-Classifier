# CIFAR-10 CNN Classifier

This project implements a Convolutional Neural Network (CNN) using PyTorch to classify images from the CIFAR-10 dataset. CIFAR-10 consists of 60,000 32Ã—32 color images across 10 categories such as airplanes, cars, birds, and cats.

## ğŸš€ Features

- Loads and preprocesses CIFAR-10 dataset using torchvision
- Custom CNN architecture with convolution, pooling, dropout, and fully connected layers
- GPU acceleration with CUDA support
- Training and validation with cross-entropy loss and Adam optimizer
- Accuracy evaluation on test dataset
- Visualization of images, predictions, and training curves

## ğŸ“‚ Project Structure

- `cifar10_cnn_solution.ipynb` â†’ Main Jupyter notebook with code and explanations
- `notebook_ims/` â†’ Sample images used for visualization in the notebook

## ğŸ—ï¸ Model Architecture

The CNN model (`Net` class) is defined as follows:

**Convolutional Layer 1**
- Input: 3 Ã— 32 Ã— 32 (RGB image)
- Conv2d: 3 â†’ 16 channels, kernel size = 3, padding = 1
- Activation: ReLU
- MaxPool2d: 2Ã—2, stride = 2 â†’ output: 16 Ã— 16 Ã— 16

**Convolutional Layer 2**
- Input: 16 Ã— 16 Ã— 16
- Conv2d: 16 â†’ 32 channels, kernel size = 3, padding = 1
- Activation: ReLU
- MaxPool2d: 2Ã—2, stride = 2 â†’ output: 32 Ã— 8 Ã— 8

**Convolutional Layer 3**
- Input: 32 Ã— 8 Ã— 8
- Conv2d: 32 â†’ 64 channels, kernel size = 3, padding = 1
- Activation: ReLU
- MaxPool2d: 2Ã—2, stride = 2 â†’ output: 64 Ã— 4 Ã— 4

**Fully Connected Layers**
- Flatten: 64 Ã— 4 Ã— 4 â†’ 1024
- Linear(1024 â†’ 500), Dropout(0.5), ReLU
- Linear(500 â†’ 10) (final output for CIFAR-10 classes)

This structure allows the network to progressively extract spatial features before flattening into a vector for classification.

## âš™ï¸ Requirements

- Python 3.8+
- PyTorch
- Torchvision
- Matplotlib
- Numpy
- Jupyter

## ğŸ“ˆ Results

The model achieves strong performance (~70â€“80% test accuracy depending on training time and hyperparameters).

Results may vary based on batch size, epochs, and dropout rate.

## ğŸ”® Future Improvements

- Use data augmentation (random crop, rotation, flip) for better generalization
- Try deeper architectures like ResNet or VGG
- Experiment with learning rate scheduling and regularization techniques

## ğŸ‘©â€ğŸ’» Author

Developed as part of a deep learning practice project using PyTorch for image classification tasks.
